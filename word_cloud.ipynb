{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy8z5UEqYcZW",
        "outputId": "da63ae88-ec00-4e1d-e965-ad315313ae32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.3)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel('/content/TenseUniqueDataset.xlsx')\n",
        "\n",
        "# Compute the length of each sentence\n",
        "df['Length'] = df['Sentence'].apply(len)\n",
        "\n",
        "# Summary statistics\n",
        "summary_stats = df['Length'].describe()\n",
        "\n",
        "# Print summary statistics\n",
        "print(summary_stats)\n",
        "\n",
        "# Plotting the distribution\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Create summary table\n",
        "ax0 = plt.subplot(121)\n",
        "ax0.axis('off')\n",
        "table1_data = summary_stats.reset_index()\n",
        "ax0.table(cellText=table1_data.values, colLabels=table1_data.columns, cellLoc='center', loc='center')\n",
        "\n",
        "# Create histogram\n",
        "ax2 = plt.subplot(122)\n",
        "ax2.hist(df['Length'], bins=20, color='red', edgecolor='black')\n",
        "ax2.set_title('Distribution of Text Length')\n",
        "ax2.set_xlabel('Length')\n",
        "ax2.set_ylabel('Count')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Filter sentences by tense\n",
        "present_sentences = df[df['Label'] == 0]\n",
        "past_sentences = df[df['Label'] == 1]\n",
        "future_sentences = df[df['Label'] == 2]\n",
        "\n",
        "# Compute the length of each sentence for each class\n",
        "present_sentences['Length'] = present_sentences['Sentence'].apply(len)\n",
        "past_sentences['Length'] = past_sentences['Sentence'].apply(len)\n",
        "future_sentences['Length'] = future_sentences['Sentence'].apply(len)\n",
        "\n",
        "# Summary statistics for each class\n",
        "present_summary_stats = present_sentences['Length'].describe()\n",
        "past_summary_stats = past_sentences['Length'].describe()\n",
        "future_summary_stats = future_sentences['Length'].describe()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"Present Sentences Summary Statistics\")\n",
        "print(present_summary_stats)\n",
        "print(\"\\nPast Sentences Summary Statistics\")\n",
        "print(past_summary_stats)\n",
        "print(\"\\nFuture Sentences Summary Statistics\")\n",
        "print(future_summary_stats)\n",
        "\n",
        "# Plotting the distribution\n",
        "plt.figure(figsize=(14, 12))\n",
        "\n",
        "# Create summary table for present sentences\n",
        "ax1 = plt.subplot(221)\n",
        "ax1.axis('off')\n",
        "present_table_data = present_summary_stats.reset_index()\n",
        "ax1.table(cellText=present_table_data.values, colLabels=present_table_data.columns, cellLoc='center', loc='center')\n",
        "ax1.set_title('Distribution of Text Length for Present Sentences')\n",
        "\n",
        "# Create histogram for present sentences\n",
        "ax2 = plt.subplot(222)\n",
        "ax2.hist(present_sentences['Length'], bins=20, color='blue', edgecolor='black')\n",
        "ax2.set_title('Distribution of Text Length for Present Sentences')\n",
        "ax2.set_xlabel('Length')\n",
        "ax2.set_ylabel('Count')\n",
        "\n",
        "# Create summary table for past sentences\n",
        "ax3 = plt.subplot(223)\n",
        "ax3.axis('off')\n",
        "past_table_data = past_summary_stats.reset_index()\n",
        "ax3.table(cellText=past_table_data.values, colLabels=past_table_data.columns, cellLoc='center', loc='center')\n",
        "ax3.set_title('Distribution of Text Length for Past Sentences')\n",
        "\n",
        "# Create histogram for past sentences\n",
        "ax4 = plt.subplot(224)\n",
        "ax4.hist(past_sentences['Length'], bins=20, color='green', edgecolor='black')\n",
        "ax4.set_title('Distribution of Text Length for Past Sentences')\n",
        "ax4.set_xlabel('Length')\n",
        "ax4.set_ylabel('Count')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plotting the distribution for future sentences\n",
        "plt.figure(figsize=(14, 12))\n",
        "\n",
        "# Create summary table for future sentences\n",
        "ax5 = plt.subplot(221)\n",
        "ax5.axis('off')\n",
        "future_table_data = future_summary_stats.reset_index()\n",
        "ax5.table(cellText=future_table_data.values, colLabels=future_table_data.columns, cellLoc='center', loc='center')\n",
        "ax5.set_title('Distribution of Text Length for Future Sentences')\n",
        "\n",
        "# Create histogram for future sentences\n",
        "ax6 = plt.subplot(222)\n",
        "ax6.hist(future_sentences['Length'], bins=20, color='red', edgecolor='black')\n",
        "ax6.set_title('Distribution of Text Length for Future Sentences')\n",
        "ax6.set_xlabel('Length')\n",
        "ax6.set_ylabel('Count')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Function to tokenize sentences\n",
        "def tokenize(sentence):\n",
        "    return re.split(r'\\s|,|;', sentence)\n",
        "\n",
        "# Tokenize and count the frequency of words for present sentences\n",
        "present_words = present_sentences['Sentence'].apply(tokenize).sum()\n",
        "present_word_counts = Counter(present_words)\n",
        "\n",
        "# Tokenize and count the frequency of words for past sentences\n",
        "past_words = past_sentences['Sentence'].apply(tokenize).sum()\n",
        "past_word_counts = Counter(past_words)\n",
        "\n",
        "# Tokenize and count the frequency of words for future sentences\n",
        "future_words = future_sentences['Sentence'].apply(tokenize).sum()\n",
        "future_word_counts = Counter(future_words)\n",
        "\n",
        "# Get the most common words\n",
        "most_common_present = present_word_counts.most_common(30)\n",
        "most_common_past = past_word_counts.most_common(30)\n",
        "most_common_future = future_word_counts.most_common(30)\n",
        "\n",
        "# Display the most frequent words\n",
        "print(\"\\nMost Frequent Words in Present Sentences:\")\n",
        "for word, freq in most_common_present:\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "print(\"\\nMost Frequent Words in Past Sentences:\")\n",
        "for word, freq in most_common_past:\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "print(\"\\nMost Frequent Words in Future Sentences:\")\n",
        "for word, freq in most_common_future:\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "# Generate word clouds\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Word cloud for present sentences\n",
        "present_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(present_word_counts)\n",
        "ax7 = plt.subplot(131)\n",
        "ax7.imshow(present_wordcloud, interpolation='bilinear')\n",
        "ax7.axis('off')\n",
        "ax7.set_title('Word Cloud for Present Sentences')\n",
        "\n",
        "# Word cloud for past sentences\n",
        "past_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(past_word_counts)\n",
        "ax8 = plt.subplot(132)\n",
        "ax8.imshow(past_wordcloud, interpolation='bilinear')\n",
        "ax8.axis('off')\n",
        "ax8.set_title('Word Cloud for Past Sentences')\n",
        "\n",
        "# Word cloud for future sentences\n",
        "future_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(future_word_counts)\n",
        "ax9 = plt.subplot(133)\n",
        "ax9.imshow(future_wordcloud, interpolation='bilinear')\n",
        "ax9.axis('off')\n",
        "ax9.set_title('Word Cloud for Future Sentences')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "A9yBiWWAYwMM",
        "outputId": "17ada4d8-77d4-4a5d-bc4b-c29b72b1f670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Sentence'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sentence'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6c2bcf3bb2fe>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Compute the length of each sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Summary statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sentence'"
          ]
        }
      ]
    }
  ]
}